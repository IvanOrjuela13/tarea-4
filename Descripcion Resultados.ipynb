{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f616b437-d003-440c-b44d-f60ffa12f305",
   "metadata": {},
   "source": [
    "# K-means e hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd5dcb64-5906-4590-9586-f0408497fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    "K-Means:\n",
    "\n",
    "Número óptimo de clusters:\n",
    "\n",
    "Según la curva del codo, el número óptimo de clusters parece ser 3, ya que es donde la curva comienza a aplanarse.\n",
    "Se confirma al aplicar K-Means con 3 clusters.\n",
    "\n",
    "Visualización de Clusters:\n",
    "\n",
    "Se muestra una visualización de los datos con los clusters asignados por K-Means.\n",
    "Los clusters se representan en función de las características escaladas, como la edad y el ingreso anual.\n",
    "\n",
    "Medidas de calidad:\n",
    "\n",
    "Puntaje de silueta: 0.379\n",
    "Índice de Calinski-Harabasz: 125.48\n",
    "Inertia: 439.77\n",
    "Davies-Bouldin Index: 0.903\n",
    "Hierarchical Clustering:\n",
    "Número óptimo de clusters:\n",
    "\n",
    "No se identifica claramente un número óptimo de clusters a partir del dendrograma. Sin embargo, se ha elegido 3 como número de clusters para comparar con K-Means.\n",
    "Visualización de Clusters:\n",
    "\n",
    "Se muestra una visualización de los datos con los clusters asignados por Hierarchical Clustering.\n",
    "Los clusters se representan en función de las características escaladas, como la edad y el ingreso anual.\n",
    "\n",
    "Medidas de calidad:\n",
    "\n",
    "Puntaje de silueta: 0.382\n",
    "Índice de Calinski-Harabasz: 110.88\n",
    "Davies-Bouldin Index: 0.988\n",
    "\n",
    "Comparación y Análisis:\n",
    "Ambos métodos generaron resultados similares en términos del número óptimo de clusters (3).\n",
    "Los puntajes de silueta son comparables entre los dos métodos, con valores ligeramente superiores para Hierarchical Clustering.\n",
    "El índice de Calinski-Harabasz es más alto para K-Means, lo que indica una mejor separación entre los clusters.\n",
    "El índice de Davies-Bouldin es ligeramente menor para K-Means, lo que sugiere una mejor separación y cohesión de los clusters.\n",
    "El coeficiente de correlación cofenética para Hierarchical Clustering es de aproximadamente 0.754, lo que indica una buena correlación entre las distancias originales y las distancias en el dendrograma.\n",
    "\n",
    "Conclusiones:\n",
    "Ambos métodos proporcionan resultados aceptables para este conjunto de datos.\n",
    "K-Means tiende a ser más eficiente computacionalmente y es más escalable para grandes conjuntos de datos.\n",
    "Hierarchical Clustering ofrece una visión jerárquica de los clusters, lo que puede ser útil para comprender la estructura de los datos en diferentes niveles de granularidad.\n",
    "La elección entre los dos métodos dependerá de las necesidades específicas del problema y las preferencias del análisis.\n",
    "*/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
